---
kind: Service
apiVersion: v1
metadata:
  name: torchserve
  labels:
    app: torchserve
spec:
  ports:
  - name: preds
    port: {{ .Values.torchserve.inference_port }}
    targetPort: ts 
  - name: mdl
    port: {{ .Values.torchserve.management_port }}
    targetPort: ts-management
  type: LoadBalancer
  selector:
    app: torchserve
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: torchserve
  labels:
    app: torchserve
spec:
  replicas: {{ .Values.deployment.replicas }}
  selector:
    matchLabels:
      app: torchserve
  template:
    metadata:
      labels:
        app: torchserve
    spec:
      volumes:
      - name: persistent-storage
        persistentVolumeClaim:
          claimName: efs-storage-claim
      containers:
      - name: torchserve
        image: {{ .Values.torchserve_image }}
        args: ["torchserve", "--start",  "--ts-config",  "/home/model-server/config.properties", "--models", "squeezenet1_1.mar"]
        ports:
        - name: ts
          containerPort: {{ .Values.torchserve.inference_port }}
        - name: ts-management
          containerPort: {{ .Values.torchserve.management_port }}
        imagePullPolicy: IfNotPresent
        volumeMounts:
          - mountPath: {{ .Values.torchserve.model_store }}
            name: persistent-storage
        resources:
          limits:
            cpu: 4
            memory: 4Gi
            nvidia.com/gpu: 1
          requests:
            cpu: "1"
            memory: 1Gi 
